{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4f83ae",
   "metadata": {},
   "source": [
    "**Example 2:** Read data from a simple text file containing space separated numbers in multiple lines. The count of numbers on each line must be same"
   ]
  },
  {
   "cell_type": "code",
   "id": "53568686",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:41:33.576924Z",
     "start_time": "2024-12-16T21:41:33.567785Z"
    }
   },
   "source": [
    "\n",
    "arr = np.genfromtxt(r\"C:\\Users\\PMLS\\Desktop\\SEM-5\\Into to DS\\Intro to DS\\NumPy\\Testing\")\n",
    "print(\"data:\\n\", arr)\n",
    "print(\"shape: \", arr.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      " [[ 1.  2.]\n",
      " [ 3.  4.]\n",
      " [ 5.  6.]\n",
      " [ 7.  8.]\n",
      " [ 9. 10.]]\n",
      "shape:  (5, 2)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "64327a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:41:48.368669Z",
     "start_time": "2024-12-16T21:41:48.357353Z"
    }
   },
   "source": [
    "# You can read the numbers as integers, by mentioning the dtype argument\n",
    "arr = np.genfromtxt(r\"C:\\Users\\PMLS\\Desktop\\SEM-5\\Into to DS\\Intro to DS\\NumPy\\Testing\", dtype=np.uint8)\n",
    "print(\"data:\\n\", arr)\n",
    "print(\"shape: \", arr.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data:\n",
      " [[ 1  2]\n",
      " [ 3  4]\n",
      " [ 5  6]\n",
      " [ 7  8]\n",
      " [ 9 10]]\n",
      "shape:  (5, 2)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "76ee4452",
   "metadata": {},
   "source": [
    "**Example 3:** Read data from a csv text file containing comma separated numbers. By default, the `genfromtxt()` expect a space as separator. So here, we need to pass `,` as the delimiter argument"
   ]
  },
  {
   "cell_type": "code",
   "id": "70a700d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:42:19.489565Z",
     "start_time": "2024-12-16T21:42:19.411361Z"
    }
   },
   "source": [
    "arr = np.genfromtxt(\"datasets/icecreamsales_simple.csv\", dtype=np.int16, delimiter=',')\n",
    "print(\"data:\\n\", arr)\n",
    "print(arr.shape)"
   ],
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "datasets/icecreamsales_simple.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m arr \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgenfromtxt\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdatasets/icecreamsales_simple.csv\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mint16\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdelimiter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m,\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, arr)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(arr\u001B[38;5;241m.\u001B[39mshape)\n",
      "File \u001B[1;32m~\\Desktop\\SEM-5\\Into to DS\\LAB\\.venv\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:1990\u001B[0m, in \u001B[0;36mgenfromtxt\u001B[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001B[0m\n\u001B[0;32m   1988\u001B[0m     fname \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mfspath(fname)\n\u001B[0;32m   1989\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(fname, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m-> 1990\u001B[0m     fid \u001B[38;5;241m=\u001B[39m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_datasource\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1991\u001B[0m     fid_ctx \u001B[38;5;241m=\u001B[39m contextlib\u001B[38;5;241m.\u001B[39mclosing(fid)\n\u001B[0;32m   1992\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\Desktop\\SEM-5\\Into to DS\\LAB\\.venv\\Lib\\site-packages\\numpy\\lib\\_datasource.py:192\u001B[0m, in \u001B[0;36mopen\u001B[1;34m(path, mode, destpath, encoding, newline)\u001B[0m\n\u001B[0;32m    155\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    156\u001B[0m \u001B[38;5;124;03mOpen `path` with `mode` and return the file object.\u001B[39;00m\n\u001B[0;32m    157\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    188\u001B[0m \n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    191\u001B[0m ds \u001B[38;5;241m=\u001B[39m DataSource(destpath)\n\u001B[1;32m--> 192\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnewline\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\SEM-5\\Into to DS\\LAB\\.venv\\Lib\\site-packages\\numpy\\lib\\_datasource.py:529\u001B[0m, in \u001B[0;36mDataSource.open\u001B[1;34m(self, path, mode, encoding, newline)\u001B[0m\n\u001B[0;32m    526\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _file_openers[ext](found, mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m    527\u001B[0m                               encoding\u001B[38;5;241m=\u001B[39mencoding, newline\u001B[38;5;241m=\u001B[39mnewline)\n\u001B[0;32m    528\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 529\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mFileNotFoundError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: datasets/icecreamsales_simple.csv not found."
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "50141593",
   "metadata": {},
   "source": [
    "**Example 4:** By default the `genfromtxt()` method assume that no column labels are there in the first line. However, if the first row of file contains column labels, we need to use skip_header argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06238c67",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "arr = np.genfromtxt(\"datasets/icecreamsales_withheader.csv\", dtype=np.int16, delimiter=',', skip_header=1)\n",
    "print(\"data:\\n\", arr)\n",
    "print(arr.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c2a7e537",
   "metadata": {},
   "source": [
    "**Example 5:** If the file has comments in the beginning, in between or at the end, you will get an error. To handle this, you need to pass the appropriate character that is used for start of comment to the comment argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e848054",
   "metadata": {},
   "source": [
    "arr = np.genfromtxt(\"datasets/icecreamsales_withcomments.csv\", dtype=np.int16, delimiter=',', comments='#')\n",
    "print(\"data:\\n\", arr)\n",
    "print(arr.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "45c14919",
   "metadata": {},
   "source": [
    "arr1 = np.array([[1.5, 2.3, 3.7], [4.0, 5.2, 6.8],[7.1, 8.4, 9.3]])\n",
    "np.savetxt('datasets/myarr.txt', arr1, fmt='%.2f')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1b85bb1",
   "metadata": {},
   "source": [
    "arr2 = np.genfromtxt(\"datasets/myarr.txt\")\n",
    "arr2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5cd32692",
   "metadata": {},
   "source": [
    "**Example 2:** Create a NumPy array and then save it as a csv file. Finally verify by reading the file contents into a numPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e425f13",
   "metadata": {},
   "source": [
    "arr1 = np.array([[1.5, 2.3, 3.7], [4.0, 5.2, 6.8],[7.1, 8.4, 9.3]])\n",
    "np.savetxt('datasets/myarr.csv', arr1, fmt='%.2f', delimiter=',')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73cb0b42",
   "metadata": {},
   "source": [
    "arr2 = np.genfromtxt(\"datasets/myarr.csv\", usecols=[0, 1], delimiter=',')\n",
    "arr2"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "6a26824e",
   "metadata": {},
   "source": [
    "## 3.  Bonus # 1\n",
    "Visit `https://gist.github.com/arifpucit` and get the URL of public `climate.csv` file from this public GitHub gist, which contains 10,000 climate measurements (temperature, rainfall & humidity) in the following format: \n",
    "\n",
    "```\n",
    "temperature,rainfall,humidity\n",
    "25.00,76.00,99.00\n",
    "39.00,65.00,70.00\n",
    "59.00,45.00,77.00\n",
    "84.00,63.00,38.00\n",
    "66.00,50.00,52.00\n",
    "41.00,94.00,77.00\n",
    "91.00,57.00,96.00\n",
    "49.00,96.00,99.00\n",
    "67.00,20.00,28.00\n",
    "...\n",
    "```\n",
    "\n",
    "Download the file and then read its data and compute the average of temperature, rainfall, and humidity values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f968121c",
   "metadata": {},
   "source": [
    "- The `urllib.request.urlretrieve(url, filename=None)` method is used to retrieve a remote file into a temporary location on disk.\n",
    "- Let us download `climate.csv` above mentioned github gist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e9c98b",
   "metadata": {},
   "source": [
    ">**The `urllib.request.urlopen()`, may return a URLError saying `SSL: CERTIFICATE_VERIFY_FAILED`. To handle this error set  the `_create_default_https_context` attribute of `ssl` to `_create_unverified_context`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a75db5e",
   "metadata": {},
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "599acc0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-16T21:44:50.788531Z",
     "start_time": "2024-12-16T21:44:49.670554Z"
    }
   },
   "source": [
    "import urllib\n",
    "#Get the raw data url from your github gist account of a csv file named climate.csv\n",
    "myurl = 'https://gist.githubusercontent.com/arifpucit/6e2d95002460db296506ec6f0cfb7008/raw/dae54a4e20d34e4b9622333fcccf04c441a250b7/climate.csv'\n",
    "\n",
    "# Pass the url string and the path, where to save the file on local disk\n",
    "urllib.request.urlretrieve(myurl, r'C:\\Users\\PMLS\\Desktop\\SEM-5\\Into to DS\\Intro to DS\\NumPy\\Testing')\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('C:\\\\Users\\\\PMLS\\\\Desktop\\\\SEM-5\\\\Into to DS\\\\Intro to DS\\\\NumPy\\\\Testing',\n",
       " <http.client.HTTPMessage at 0x167aa14a720>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd407657",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "climate_data = np.genfromtxt(\"datasets/climate.csv\", delimiter=',', skip_header=1)\n",
    "print(\"Climate Data:\\n\", climate_data)\n",
    "print(climate_data.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6342cbe8",
   "metadata": {},
   "source": [
    "# Slice data of the temperature column\n",
    "climate_data[:,0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86545bbb",
   "metadata": {},
   "source": [
    "# Slice data of the rainfall column\n",
    "climate_data[:,1]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2403f0e0",
   "metadata": {},
   "source": [
    "# Slice data of the humidity column\n",
    "climate_data[:,2]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c19fb85b",
   "metadata": {},
   "source": [
    "# Calculate the Mean of every column\n",
    "print(\"Mean Temperature = \", climate_data[:,0].mean())\n",
    "print(\"Mean Rainfall = \", climate_data[:,1].mean())\n",
    "print(\"Mean Humidity = \", climate_data[:,2].mean())"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c010ee34",
   "metadata": {},
   "source": [
    ">- Let us now create a fourth column, that is the sum obtained by matrix multiplication of climate_data and their corresponding hypothetical weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf3a5c7d",
   "metadata": {},
   "source": [
    "weights = np.array([0.3, 0.2, 0.5])\n",
    "new_col = np.matmul(climate_data, weights)\n",
    "new_col"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34a91e3a",
   "metadata": {},
   "source": [
    "new_col.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "ff89587a",
   "metadata": {},
   "source": [
    "Let's add the `new_col` to `climate_data` as a fourth column using the `np.concatenate`\n",
    "Since we wish to add new columns, i.e., horizontally concatenate, so we pass the argument `axis=1` to `np.concatenate`. The `axis` argument specifies the dimension for concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2451a1c9",
   "metadata": {},
   "source": [
    "# First we need to reshape() the new_col to a 10000x1 matrix for concatenation\n",
    "result_data = new_col.reshape(10000, 1)\n",
    "result_data, result_data.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9c029f34",
   "metadata": {},
   "source": [
    "climate_results = np.concatenate((climate_data, result_data), axis=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b23178e9",
   "metadata": {},
   "source": [
    "climate_results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b24ff52",
   "metadata": {},
   "source": [
    "climate_results.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "bd2dd41f",
   "metadata": {},
   "source": [
    "The results are written back in the CSV format to the file `climate_results.csv`. \n",
    "\n",
    "```\n",
    "temperature,rainfall,humidity,col4\n",
    "25.00,76.00,99.00,72.20\n",
    "39.00,65.00,70.00,59.70\n",
    "59.00,45.00,77.00,65.20\n",
    "84.00,63.00,38.00,56.80\n",
    "...\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f9df4",
   "metadata": {},
   "source": [
    ">- Let's write back the resulting numPy array `climate_results` in a new file `climate_results.csv` using the `np.savetxt` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2db36782",
   "metadata": {},
   "source": [
    "np.savetxt('datasets/climate_results.csv', \n",
    "           climate_results, \n",
    "           fmt='%.2f', \n",
    "           delimiter=',',\n",
    "           header='temperature,rainfall,humidity,col4', \n",
    "           comments='')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34fe6e06",
   "metadata": {},
   "source": [
    "! cat datasets/climate_results.csv"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c4d6c1b8",
   "metadata": {},
   "source": [
    "## 4.  Bonus # 2\n",
    "Now let us read an image file from disk and load it into a numPy array for image processing task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "92a6e67e",
   "metadata": {},
   "source": [
    "from PIL import Image"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53b46a8f",
   "metadata": {},
   "source": [
    "rgb_img = Image.open(\"datasets/speech.jpg\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfb17824",
   "metadata": {},
   "source": [
    "rgb_img.mode"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe068dcd",
   "metadata": {},
   "source": [
    "rgb_img.size"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d9d64c7d",
   "metadata": {},
   "source": [
    "When translating a color image to greyscale (mode \"L\"), the library uses the ITU-R 601-2 luma transform::\n",
    "```\n",
    "    L = R * 299/1000 + G * 587/1000 + B * 114/1000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c605c127",
   "metadata": {},
   "source": [
    "grey_img = rgb_img.convert('L')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a2fed8de",
   "metadata": {},
   "source": [
    "grey_img.mode"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4d96848a",
   "metadata": {},
   "source": [
    "grey_img.size"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f88251d",
   "metadata": {},
   "source": [
    "rgb_img"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "69664262",
   "metadata": {},
   "source": [
    "grey_img"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "97616bb7",
   "metadata": {},
   "source": [
    "#### Let us convert the two images to a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eb796f4",
   "metadata": {},
   "source": [
    "rgb_img_array = np.array(rgb_img)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "171eac4a",
   "metadata": {},
   "source": [
    "rgb_img_array.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23aa3881",
   "metadata": {},
   "source": [
    "rgb_img_array"
   ],
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 48,
   "source": "grey_img_array = np.array(grey_img)",
   "id": "6668464c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 49,
   "source": "grey_img_array.shape",
   "id": "ae32ca23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 50,
   "source": "grey_img_array",
   "id": "a30a77a0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
